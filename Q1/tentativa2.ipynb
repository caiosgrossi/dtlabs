{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c9cca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268b1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_point_cloud(file_path):\n",
    "    \"\"\"Carrega a nuvem de pontos usando Trimesh e retorna os vértices como tensor no dispositivo configurado.\"\"\"\n",
    "    mesh = trimesh.load(file_path)\n",
    "    vertices = mesh.vertices\n",
    "    return torch.tensor(vertices, dtype=torch.float32, device=device)\n",
    "\n",
    "def cdist_batched(src, target, batch_size=512):\n",
    "    results = []\n",
    "    for i in range(0, src.shape[0], batch_size):\n",
    "        src_batch = src[i:i+batch_size]\n",
    "        d = torch.cdist(src_batch, target)\n",
    "        results.append(d)\n",
    "    return torch.cat(results, dim=0)\n",
    "\n",
    "\n",
    "def icp(source, target, max_iter=50, tol=1e-5):\n",
    "    \"\"\"Implementa o algoritmo ICP para alinhar a nuvem de pontos 'source' à 'target'.\"\"\"\n",
    "    T_total = torch.eye(4, device=device)\n",
    "    src = source.clone()\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        # 1. Encontrar correspondências entre os pontos usando torch.cdist\n",
    "        distances = cdist_batched(src, target)\n",
    "        indices = torch.argmin(distances, dim=1)\n",
    "        target_corr = target[indices]\n",
    "        \n",
    "        # 2. Calcular os centróides\n",
    "        centroid_src = src.mean(dim=0)\n",
    "        centroid_target = target_corr.mean(dim=0)\n",
    "        \n",
    "        # 3. Centralizar os pontos\n",
    "        src_centered = src - centroid_src\n",
    "        target_centered = target_corr - centroid_target\n",
    "        \n",
    "        # 4. Calcular a matriz de covariância\n",
    "        H = src_centered.t() @ target_centered\n",
    "        U, S, Vt = torch.linalg.svd(H)\n",
    "        R = Vt.t() @ U.t()\n",
    "        \n",
    "        # Corrigir reflexão, se necessário\n",
    "        if torch.det(R) < 0:\n",
    "            Vt[-1, :] *= -1\n",
    "            R = Vt.t() @ U.t()\n",
    "        \n",
    "        # 5. Calcular a translação\n",
    "        t = centroid_target - R @ centroid_src\n",
    "        \n",
    "        # 6. Formar a matriz de transformação homogênea\n",
    "        T = torch.eye(4, device=device)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = t\n",
    "        \n",
    "        # 7. Aplicar a transformação na nuvem de pontos source\n",
    "        ones = torch.ones(src.shape[0], 1, device=device)\n",
    "        src_h = torch.cat([src, ones], dim=1)  # converter para coordenadas homogêneas\n",
    "        src_h = (T @ src_h.t()).t()\n",
    "        src = src_h[:, :3]\n",
    "        \n",
    "        # Acumular a transformação\n",
    "        T_total = T @ T_total\n",
    "        \n",
    "        # Critério de convergência: se a média dos valores singulares for menor que tol\n",
    "        if S.mean() < tol:\n",
    "            break\n",
    "    \n",
    "    return T_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dff3fe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.53 GiB. GPU 0 has a total capacity of 23.56 GiB of which 8.66 GiB is free. Including non-PyTorch memory, this process has 14.89 GiB memory in use. Of the allocated memory 14.57 GiB is allocated by PyTorch, and 13.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m source \u001b[38;5;241m=\u001b[39m load_point_cloud(source_file)\n\u001b[1;32m     17\u001b[0m target \u001b[38;5;241m=\u001b[39m load_point_cloud(target_file)\n\u001b[0;32m---> 19\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[43micp\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m T_acc \u001b[38;5;241m=\u001b[39m T \u001b[38;5;241m@\u001b[39m trajectory[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     21\u001b[0m trajectory\u001b[38;5;241m.\u001b[39mappend(T_acc)\n",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m, in \u001b[0;36micp\u001b[0;34m(source, target, max_iter, tol)\u001b[0m\n\u001b[1;32m     19\u001b[0m src \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# 1. Encontrar correspondências entre os pontos usando torch.cdist\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43mcdist_batched\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmin(distances, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m     target_corr \u001b[38;5;241m=\u001b[39m target[indices]\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mcdist_batched\u001b[0;34m(src, target, batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m     d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcdist(src_batch, target)\n\u001b[1;32m     12\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(d)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.53 GiB. GPU 0 has a total capacity of 23.56 GiB of which 8.66 GiB is free. Including non-PyTorch memory, this process has 14.89 GiB memory in use. Of the allocated memory 14.57 GiB is allocated by PyTorch, and 13.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Defina o diretório base dos arquivos\n",
    "point_cloud_dir = \"objetos/KITTI-Sequence\"  # Diretório base onde estão as pastas dos scans\n",
    "ground_truth_file = \"./ground_truth.npy\"  # Mantenha ou ajuste se necessário\n",
    "\n",
    "num_scans = 10\n",
    "trajectory = [torch.eye(4, device=device)]\n",
    "\n",
    "for i in range(1, num_scans):\n",
    "    source_file = os.path.join(point_cloud_dir, f\"{i-1:06d}\", f\"{i-1:06d}_points.obj\")\n",
    "    target_file = os.path.join(point_cloud_dir, f\"{i:06d}\", f\"{i:06d}_points.obj\")\n",
    "    \n",
    "    if not os.path.exists(source_file) or not os.path.exists(target_file):\n",
    "        print(f\"Arquivo não encontrado: {source_file} ou {target_file}\")\n",
    "        continue\n",
    "\n",
    "    source = load_point_cloud(source_file)\n",
    "    target = load_point_cloud(target_file)\n",
    "\n",
    "    T = icp(source, target)\n",
    "    T_acc = T @ trajectory[-1]\n",
    "    trajectory.append(T_acc)\n",
    "\n",
    "# Libera as variáveis usadas neste loop\n",
    "del source, target, T\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "\n",
    "\n",
    "# Converter as matrizes de transformação para CPU para visualização\n",
    "trajectory_cpu = [T.cpu().numpy() for T in trajectory]\n",
    "positions = np.array([T[:3, 3] for T in trajectory_cpu])\n",
    "\n",
    "# Plotar a trajetória estimada em 3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(positions[:, 0], positions[:, 1], positions[:, 2], marker='o')\n",
    "ax.set_title(\"Trajetória Estimada do Veículo\")\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "plt.show()\n",
    "\n",
    "# Carregar a ground truth e comparar\n",
    "if os.path.exists(ground_truth_file):\n",
    "    ground_truth = np.load(ground_truth_file)  # Espera-se um array de tamanho (30, 4, 4)\n",
    "    errors = []\n",
    "    for T_est, T_gt in zip(trajectory_cpu, ground_truth):\n",
    "        pos_est = T_est[:3, 3]\n",
    "        pos_gt = T_gt[:3, 3]\n",
    "        error = np.linalg.norm(pos_est - pos_gt)\n",
    "        errors.append(error)\n",
    "    print(\"Erro médio de translação:\", np.mean(errors))\n",
    "else:\n",
    "    print(\"Arquivo de ground truth não encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e8b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'reorient_points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Exemplo de uso:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjetos/KITTI-Sequence/000000/000000_points.obj\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 24\u001b[0m pcd \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_reorient_point_cloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle_degrees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m o3d\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mdraw_geometries([pcd])\n",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m, in \u001b[0;36mload_and_reorient_point_cloud\u001b[0;34m(file_path, angle_degrees, axis)\u001b[0m\n\u001b[1;32m     13\u001b[0m vertices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(vertices)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Reorientar os pontos (teste diferentes ângulos e eixos)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m vertices_reoriented \u001b[38;5;241m=\u001b[39m \u001b[43mreorient_points\u001b[49m(vertices, angle_degrees, axis)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Converter para PointCloud do Open3D\u001b[39;00m\n\u001b[1;32m     18\u001b[0m pcd \u001b[38;5;241m=\u001b[39m o3d\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mPointCloud()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reorient_points' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HIV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
